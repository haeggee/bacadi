

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>cdt.causality.graph.SAM &mdash; Causal Discovery Toolbox 0.5.22 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.png"/>
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"extensions": ["tex2jax.js"], "jax": ["input/TeX", "output/HTML-CSS"], "tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "displayMath": [["$$", "$$"], ["\\[", "\\]"]], "processEscapes": true}, "HTML-CSS": {"fonts": ["TeX"]}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html">
          

          
            
            <img src="../../../../_static/banner.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.5.22
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../index.html">Causal Discovery Toolbox Documentation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial.html">Get started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../causality.html">cdt.causality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../independence.html">cdt.independence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">cdt.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">cdt.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../metrics.html">cdt.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../settings.html">Toolbox Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">PyTorch Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../developer.html">Developer Documentation</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Causal Discovery Toolbox</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>cdt.causality.graph.SAM</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for cdt.causality.graph.SAM</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Structural Agnostic Model.</span>

<span class="sd">Author: Diviyan Kalainathan, Olivier Goudet</span>
<span class="sd">Date: 09/3/2018</span>

<span class="sd">.. MIT License</span>
<span class="sd">..</span>
<span class="sd">.. Copyright (c) 2018 Diviyan Kalainathan</span>
<span class="sd">..</span>
<span class="sd">.. Permission is hereby granted, free of charge, to any person obtaining a copy</span>
<span class="sd">.. of this software and associated documentation files (the &quot;Software&quot;), to deal</span>
<span class="sd">.. in the Software without restriction, including without limitation the rights</span>
<span class="sd">.. to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span>
<span class="sd">.. copies of the Software, and to permit persons to whom the Software is</span>
<span class="sd">.. furnished to do so, subject to the following conditions:</span>
<span class="sd">..</span>
<span class="sd">.. The above copyright notice and this permission notice shall be included in all</span>
<span class="sd">.. copies or substantial portions of the Software.</span>
<span class="sd">..</span>
<span class="sd">.. THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="sd">.. IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="sd">.. FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span>
<span class="sd">.. AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="sd">.. LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span>
<span class="sd">.. OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span>
<span class="sd">.. SOFTWARE.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">.model</span> <span class="kn">import</span> <span class="n">GraphModel</span>
<span class="kn">from</span> <span class="nn">...utils.parallel</span> <span class="kn">import</span> <span class="n">parallel_run</span>
<span class="kn">from</span> <span class="nn">...utils.loss</span> <span class="kn">import</span> <span class="n">notears_constr</span>
<span class="kn">from</span> <span class="nn">...utils.torch</span> <span class="kn">import</span> <span class="n">ChannelBatchNorm1d</span><span class="p">,</span> <span class="n">MatrixSampler</span><span class="p">,</span> <span class="n">Linear3D</span>
<span class="kn">from</span> <span class="nn">...utils.Settings</span> <span class="kn">import</span> <span class="n">SETTINGS</span>


<div class="viewcode-block" id="SAM_generators"><a class="viewcode-back" href="../../../../models.html#cdt.causality.graph.SAM_generators">[docs]</a><span class="k">class</span> <span class="nc">SAM_generators</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Ensemble of all the SAM generators.</span>

<span class="sd">    Args:</span>
<span class="sd">        data_shape (tuple): Shape of the true data</span>
<span class="sd">        nh (int): Initial number of hidden units in the hidden layers</span>
<span class="sd">        skeleton (numpy.ndarray): Initial skeleton, defaults to a fully connected graph</span>
<span class="sd">        linear (bool): Enables the linear variant</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_shape</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="n">skeleton</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">linear</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Init the model.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SAM_generators</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Building skeleton</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">linear</span>
        <span class="n">nb_vars</span> <span class="o">=</span> <span class="n">data_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nb_vars</span> <span class="o">=</span> <span class="n">nb_vars</span>
        <span class="k">if</span> <span class="n">skeleton</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">skeleton</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">th</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nb_vars</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nb_vars</span><span class="p">)</span>  <span class="c1"># 1 row for noise</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">skeleton</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">skeleton</span><span class="p">),</span> <span class="n">th</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nb_vars</span><span class="p">)],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">linear</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">Linear3D</span><span class="p">((</span><span class="n">nb_vars</span><span class="p">,</span> <span class="n">nb_vars</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">Linear3D</span><span class="p">((</span><span class="n">nb_vars</span><span class="p">,</span> <span class="n">nb_vars</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nh</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ChannelBatchNorm1d</span><span class="p">(</span><span class="n">nb_vars</span><span class="p">,</span> <span class="n">nh</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">Linear3D</span><span class="p">((</span><span class="n">nb_vars</span><span class="p">,</span> <span class="n">nh</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;skeleton&#39;</span><span class="p">,</span> <span class="n">skeleton</span><span class="p">)</span>

<div class="viewcode-block" id="SAM_generators.forward"><a class="viewcode-back" href="../../../../models.html#cdt.causality.graph.SAM_generators.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">,</span> <span class="n">drawn_neurons</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Forward through all the generators.</span>

<span class="sd">        Args:</span>
<span class="sd">            data (torch.Tensor): True data</span>
<span class="sd">            noise (torch.Tensor): Samples of noise variables</span>
<span class="sd">            adj_matrix (torch.Tensor): Sampled adjacency matrix</span>
<span class="sd">            drawn_neurons (torch.Tensor): Sampled matrix of active neurons</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Batch of generated data</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">adj_matrix</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">skeleton</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">data</span><span class="p">,</span>
                                                                    <span class="n">noise</span><span class="p">,</span>
                                                                    <span class="n">adj_matrix</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">skeleton</span><span class="p">)),</span>
                                       <span class="n">drawn_neurons</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;reset_parameters&#39;</span><span class="p">):</span>
                    <span class="n">layer</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span></div>


<div class="viewcode-block" id="SAM_discriminator"><a class="viewcode-back" href="../../../../models.html#cdt.causality.graph.SAM_discriminator">[docs]</a><span class="k">class</span> <span class="nc">SAM_discriminator</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;SAM discriminator.</span>

<span class="sd">    Args:</span>
<span class="sd">        nfeatures (int): Number of variables in the dataset</span>
<span class="sd">        dnh (int): Number of hidden units in the hidden layers</span>
<span class="sd">        hlayers (int): Number of hidden layers</span>
<span class="sd">        mask (numpy.ndarray): Mask of connections to ignore</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nfeatures</span><span class="p">,</span> <span class="n">dnh</span><span class="p">,</span> <span class="n">hlayers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SAM_discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nfeatures</span> <span class="o">=</span> <span class="n">nfeatures</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nfeatures</span><span class="p">,</span> <span class="n">dnh</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">dnh</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="o">.</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hlayers</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dnh</span><span class="p">,</span> <span class="n">dnh</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">dnh</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="o">.</span><span class="mi">2</span><span class="p">))</span>

        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dnh</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nfeatures</span><span class="p">,</span> <span class="n">nfeatures</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;mask&quot;</span><span class="p">,</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

<div class="viewcode-block" id="SAM_discriminator.forward"><a class="viewcode-back" href="../../../../models.html#cdt.causality.graph.SAM_discriminator.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">obs_data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Forward pass in the discriminator.</span>

<span class="sd">        Args:</span>
<span class="sd">            input (torch.Tensor): True Data or generated data</span>
<span class="sd">            obs_data (torch.Tensor): True data in the case of `input=generated` for padding.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Output of the discriminator</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">obs_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">th</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">obs_data</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">)</span>
                                                      <span class="o">+</span> <span class="nb">input</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;reset_parameters&#39;</span><span class="p">):</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span></div>


<span class="k">def</span> <span class="nf">run_SAM</span><span class="p">(</span><span class="n">in_data</span><span class="p">,</span> <span class="n">skeleton</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
            <span class="n">train</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_gen</span><span class="o">=.</span><span class="mi">001</span><span class="p">,</span>
            <span class="n">lr_disc</span><span class="o">=.</span><span class="mi">01</span><span class="p">,</span> <span class="n">lambda1</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">lambda2</span><span class="o">=</span><span class="mf">0.0000001</span><span class="p">,</span> <span class="n">nh</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dnh</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">losstype</span><span class="o">=</span><span class="s2">&quot;fgan&quot;</span><span class="p">,</span>
            <span class="n">dagstart</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dagloss</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">dagpenalization</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">dagpenalization_increase</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">linear</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">hlayers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="n">list_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">in_data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">in_data</span><span class="p">[</span><span class="n">list_nodes</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">nb_var</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_nodes</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="c1"># Get the list of indexes to ignore</span>
    <span class="k">if</span> <span class="n">skeleton</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">skeleton</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">skeleton</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>

    <span class="n">sam</span> <span class="o">=</span> <span class="n">SAM_generators</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">cols</span><span class="p">),</span> <span class="n">nh</span><span class="p">,</span> <span class="n">skeleton</span><span class="o">=</span><span class="n">skeleton</span><span class="p">,</span>
                         <span class="n">linear</span><span class="o">=</span><span class="n">linear</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">sam</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
    <span class="n">g_optimizer</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">sam</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_gen</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">losstype</span> <span class="o">!=</span> <span class="s2">&quot;mse&quot;</span><span class="p">:</span>
        <span class="n">discriminator</span> <span class="o">=</span> <span class="n">SAM_discriminator</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="n">dnh</span><span class="p">,</span> <span class="n">hlayers</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">discriminator</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
        <span class="n">d_optimizer</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_disc</span><span class="p">)</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">graph_sampler</span> <span class="o">=</span> <span class="n">MatrixSampler</span><span class="p">(</span><span class="n">nb_var</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">skeleton</span><span class="p">,</span>
                                  <span class="n">gumbel</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">graph_sampler</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">graph_optimizer</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">graph_sampler</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_gen</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">linear</span><span class="p">:</span>
        <span class="n">neuron_sampler</span> <span class="o">=</span> <span class="n">MatrixSampler</span><span class="p">((</span><span class="n">nh</span><span class="p">,</span> <span class="n">nb_var</span><span class="p">),</span> <span class="n">mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                       <span class="n">gumbel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">neuron_optimizer</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">neuron_sampler</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
                                         <span class="n">lr</span><span class="o">=</span><span class="n">lr_gen</span><span class="p">)</span>

    <span class="n">_true</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">_false</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nb_var</span><span class="p">,</span> <span class="n">nb_var</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">noise</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">nb_var</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">noise_row</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nb_var</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">data_iterator</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                               <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># RUN</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">train</span> <span class="o">+</span> <span class="n">test</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">train</span><span class="o">+</span><span class="n">test</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i_batch</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_iterator</span><span class="p">):</span>
            <span class="n">g_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">losstype</span> <span class="o">!=</span> <span class="s2">&quot;mse&quot;</span><span class="p">:</span>
                <span class="n">d_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">linear</span><span class="p">:</span>
                <span class="n">neuron_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Train the discriminator</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="n">train</span><span class="p">:</span>
                <span class="n">drawn_graph</span> <span class="o">=</span> <span class="n">graph_sampler</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">linear</span><span class="p">:</span>
                    <span class="n">drawn_neurons</span> <span class="o">=</span> <span class="n">neuron_sampler</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">drawn_neurons</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">noise</span><span class="o">.</span><span class="n">normal_</span><span class="p">()</span>
            <span class="n">generated_variables</span> <span class="o">=</span> <span class="n">sam</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span>
                                      <span class="n">th</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">drawn_graph</span><span class="p">,</span> <span class="n">noise_row</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span>
                                      <span class="n">drawn_neurons</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">losstype</span> <span class="o">==</span> <span class="s2">&quot;mse&quot;</span><span class="p">:</span>
                <span class="n">gen_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">generated_variables</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">disc_vars_d</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">generated_variables</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">batch</span><span class="p">)</span>
                <span class="n">disc_vars_g</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">generated_variables</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
                <span class="n">true_vars_disc</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">losstype</span> <span class="o">==</span> <span class="s2">&quot;gan&quot;</span><span class="p">:</span>
                    <span class="n">disc_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">criterion</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span> <span class="n">_false</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">gen</span><span class="p">))</span> <span class="k">for</span> <span class="n">gen</span> <span class="ow">in</span> <span class="n">disc_vars_d</span><span class="p">])</span> <span class="o">/</span> <span class="n">nb_var</span> \
                                     <span class="o">+</span> <span class="n">criterion</span><span class="p">(</span><span class="n">true_vars_disc</span><span class="p">,</span> <span class="n">_true</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">true_vars_disc</span><span class="p">))</span>
                    <span class="c1"># Gen Losses per generator: multiply py the number of channels</span>
                    <span class="n">gen_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">criterion</span><span class="p">(</span><span class="n">gen</span><span class="p">,</span>
                                              <span class="n">_true</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">gen</span><span class="p">))</span>
                                    <span class="k">for</span> <span class="n">gen</span> <span class="ow">in</span> <span class="n">disc_vars_g</span><span class="p">])</span>
                <span class="k">elif</span> <span class="n">losstype</span> <span class="o">==</span> <span class="s2">&quot;fgan&quot;</span><span class="p">:</span>

                    <span class="n">disc_loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">th</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">gen</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">gen</span> <span class="ow">in</span> <span class="n">disc_vars_d</span><span class="p">])</span> <span class="o">/</span> <span class="n">nb_var</span> <span class="o">-</span> <span class="n">th</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">true_vars_disc</span><span class="p">)</span>
                    <span class="n">gen_loss</span> <span class="o">=</span> <span class="o">-</span><span class="nb">sum</span><span class="p">([</span><span class="n">th</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">gen</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">gen</span> <span class="ow">in</span> <span class="n">disc_vars_g</span><span class="p">])</span>

                <span class="n">disc_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">d_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">filters</span> <span class="o">=</span> <span class="n">graph_sampler</span><span class="o">.</span><span class="n">get_proba</span><span class="p">()</span>

            <span class="n">struc_loss</span> <span class="o">=</span> <span class="n">lambda1</span><span class="o">*</span><span class="n">drawn_graph</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

            <span class="n">func_loss</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">linear</span> <span class="k">else</span> <span class="n">lambda2</span><span class="o">*</span><span class="n">drawn_neurons</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">regul_loss</span> <span class="o">=</span> <span class="n">struc_loss</span> <span class="o">+</span> <span class="n">func_loss</span>

            <span class="k">if</span> <span class="n">dagloss</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="n">train</span> <span class="o">*</span> <span class="n">dagstart</span><span class="p">:</span>
                <span class="n">dag_constraint</span> <span class="o">=</span> <span class="n">notears_constr</span><span class="p">(</span><span class="n">filters</span><span class="o">*</span><span class="n">filters</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">gen_loss</span> <span class="o">+</span> <span class="n">regul_loss</span> <span class="o">+</span> <span class="p">(</span><span class="n">dagpenalization</span> <span class="o">+</span>
                                                <span class="p">(</span><span class="n">epoch</span> <span class="o">-</span> <span class="n">train</span> <span class="o">*</span> <span class="n">dagstart</span><span class="p">)</span>
                                                <span class="o">*</span> <span class="n">dagpenalization_increase</span><span class="p">)</span> <span class="o">*</span> <span class="n">dag_constraint</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">gen_loss</span> <span class="o">+</span> <span class="n">regul_loss</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">i_batch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">gen</span><span class="o">=</span><span class="n">gen_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">/</span><span class="n">cols</span><span class="p">,</span>
                                 <span class="n">disc</span><span class="o">=</span><span class="n">disc_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                 <span class="n">regul_loss</span><span class="o">=</span><span class="n">regul_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                                 <span class="n">tot</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="k">if</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="n">train</span> <span class="o">+</span> <span class="n">test</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;=</span> <span class="n">train</span><span class="p">:</span>
                <span class="n">output</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">filters</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

            <span class="n">g_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">linear</span><span class="p">:</span>
                <span class="n">neuron_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="n">test</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


<div class="viewcode-block" id="SAM"><a class="viewcode-back" href="../../../../causality.html#cdt.causality.graph.SAM">[docs]</a><span class="k">class</span> <span class="nc">SAM</span><span class="p">(</span><span class="n">GraphModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;SAM Algorithm.</span>

<span class="sd">    **Description:** Structural Agnostic Model is an causal discovery algorithm</span>
<span class="sd">    for DAG recovery leveraging both distributional asymetries and conditional</span>
<span class="sd">    independencies. the first version of SAM without DAG constraint is available</span>
<span class="sd">    as ``SAMv1``.</span>

<span class="sd">    **Data Type:** Continuous</span>

<span class="sd">    **Assumptions:** The class of generative models is not restricted with a</span>
<span class="sd">    hard contraint, but with soft constraints parametrized with the ``lambda1``</span>
<span class="sd">    and ``lambda2`` parameters, with gumbel softmax sampling. This algorithms greatly</span>
<span class="sd">    benefits from bootstrapped runs (nruns &gt;=8 recommended).</span>
<span class="sd">    GPUs are recommended but not compulsory. The output is a DAG, but may need a</span>
<span class="sd">    thresholding as the output is averaged over multiple runs.</span>

<span class="sd">    Args:</span>
<span class="sd">        lr (float): Learning rate of the generators</span>
<span class="sd">        dlr (float): Learning rate of the discriminator</span>
<span class="sd">        lambda1 (float): L0 penalization coefficient on the causal filters</span>
<span class="sd">        lambda2 (float): L0 penalization coefficient on the hidden units of the</span>
<span class="sd">           neural network</span>
<span class="sd">        nh (int): Number of hidden units in the generators&#39; hidden layers</span>
<span class="sd">           (regularized with lambda2)</span>
<span class="sd">        dnh (int): Number of hidden units in the discriminator&#39;s hidden layer</span>
<span class="sd">        train_epochs (int): Number of training epochs</span>
<span class="sd">        test_epochs (int): Number of test epochs (saving and averaging</span>
<span class="sd">           the causal filters)</span>
<span class="sd">        batch_size (int): Size of the batches to be fed to the SAM model.</span>
<span class="sd">           Defaults to full-batch.</span>
<span class="sd">        losstype (str): type of the loss to be used (either &#39;fgan&#39; (default),</span>
<span class="sd">           &#39;gan&#39; or &#39;mse&#39;).</span>
<span class="sd">        hlayers (int): Defines the number of hidden layers in the discriminator.</span>
<span class="sd">        dagloss (bool): Activate the DAG with No-TEARS constraint.</span>
<span class="sd">        dagstart (float): Controls when the DAG constraint is to be introduced</span>
<span class="sd">           in the training (float ranging from 0 to 1, 0 denotes the start of</span>
<span class="sd">           the training and 1 the end).</span>
<span class="sd">        dagpenalisation (float): Initial value of the DAG constraint.</span>
<span class="sd">        dagpenalisation_increase (float): Increase incrementally at each epoch</span>
<span class="sd">           the coefficient of the constraint.</span>
<span class="sd">        linear (bool): If true, all generators are set to be linear generators.</span>
<span class="sd">        nruns (int): Number of runs to be made for causal estimation.</span>
<span class="sd">               Recommended: &gt;=8 for optimal performance.</span>
<span class="sd">        njobs (int): Numbers of jobs to be run in Parallel.</span>
<span class="sd">               Recommended: 1 if no GPU available, 2*number of GPUs else.</span>
<span class="sd">        gpus (int): Number of available GPUs for the algorithm.</span>
<span class="sd">        verbose (bool): verbose mode</span>

<span class="sd">    .. note::</span>
<span class="sd">       Ref: Kalainathan, Diviyan &amp; Goudet, Olivier &amp; Guyon, Isabelle &amp;</span>
<span class="sd">       Lopez-Paz, David &amp; Sebag, Michèle. (2018). Structural Agnostic Modeling:</span>
<span class="sd">       Adversarial Learning of Causal Graphs.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import networkx as nx</span>
<span class="sd">        &gt;&gt;&gt; from cdt.causality.graph import SAM</span>
<span class="sd">        &gt;&gt;&gt; from cdt.data import load_dataset</span>
<span class="sd">        &gt;&gt;&gt; data, graph = load_dataset(&quot;sachs&quot;)</span>
<span class="sd">        &gt;&gt;&gt; obj = SAM()</span>
<span class="sd">        &gt;&gt;&gt; #The predict() method works without a graph, or with a</span>
<span class="sd">        &gt;&gt;&gt; #directed or undirected graph provided as an input</span>
<span class="sd">        &gt;&gt;&gt; output = obj.predict(data)    #No graph provided as an argument</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; output = obj.predict(data, nx.Graph(graph))  #With an undirected graph</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; output = obj.predict(data, graph)  #With a directed graph</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; #To view the graph created, run the below commands:</span>
<span class="sd">        &gt;&gt;&gt; nx.draw_networkx(output, font_size=8)</span>
<span class="sd">        &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">dlr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">lambda1</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">lambda2</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">,</span> <span class="n">nh</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">dnh</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                 <span class="n">train_epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">test_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batchsize</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">losstype</span><span class="o">=</span><span class="s2">&quot;fgan&quot;</span><span class="p">,</span> <span class="n">dagstart</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dagloss</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dagpenalization</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">dagpenalization_increase</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">linear</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">hlayers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">njobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gpus</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nruns</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Init and parametrize the SAM model.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SAM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dlr</span> <span class="o">=</span> <span class="n">dlr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda1</span> <span class="o">=</span> <span class="n">lambda1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda2</span> <span class="o">=</span> <span class="n">lambda2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nh</span> <span class="o">=</span> <span class="n">nh</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dnh</span> <span class="o">=</span> <span class="n">dnh</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">test_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batchsize</span> <span class="o">=</span> <span class="n">batchsize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losstype</span> <span class="o">=</span> <span class="n">losstype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dagstart</span> <span class="o">=</span> <span class="n">dagstart</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dagloss</span> <span class="o">=</span> <span class="n">dagloss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dagpenalization</span> <span class="o">=</span> <span class="n">dagpenalization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dagpenalization_increase</span> <span class="o">=</span> <span class="n">dagpenalization_increase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">linear</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hlayers</span> <span class="o">=</span> <span class="n">hlayers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">njobs</span> <span class="o">=</span> <span class="n">SETTINGS</span><span class="o">.</span><span class="n">get_default</span><span class="p">(</span><span class="n">njobs</span><span class="o">=</span><span class="n">njobs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gpus</span> <span class="o">=</span> <span class="n">SETTINGS</span><span class="o">.</span><span class="n">get_default</span><span class="p">(</span><span class="n">gpu</span><span class="o">=</span><span class="n">gpus</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">SETTINGS</span><span class="o">.</span><span class="n">get_default</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nruns</span> <span class="o">=</span> <span class="n">nruns</span>

<div class="viewcode-block" id="SAM.predict"><a class="viewcode-back" href="../../../../causality.html#cdt.causality.graph.SAM.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">return_list_results</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Execute SAM on a dataset given a skeleton or not.</span>

<span class="sd">        Args:</span>
<span class="sd">            data (pandas.DataFrame): Observational data for estimation of causal relationships by SAM</span>
<span class="sd">            skeleton (numpy.ndarray): A priori knowledge about the causal relationships as an adjacency matrix.</span>
<span class="sd">                      Can be fed either directed or undirected links.</span>
<span class="sd">        Returns:</span>
<span class="sd">            networkx.DiGraph: Graph estimated by SAM, where A[i,j] is the term</span>
<span class="sd">            of the ith variable for the jth generator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">graph</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">skeleton</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span>
                                                     <span class="n">nodelist</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">skeleton</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">nruns</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gpus</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">run_SAM</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">skeleton</span><span class="o">=</span><span class="n">skeleton</span><span class="p">,</span>
                               <span class="n">lr_gen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
                               <span class="n">lr_disc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dlr</span><span class="p">,</span>
                               <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                               <span class="n">lambda1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda1</span><span class="p">,</span> <span class="n">lambda2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda2</span><span class="p">,</span>
                               <span class="n">nh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">,</span> <span class="n">dnh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dnh</span><span class="p">,</span>
                               <span class="n">train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                               <span class="n">test</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batchsize</span><span class="p">,</span>
                               <span class="n">dagstart</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dagstart</span><span class="p">,</span>
                               <span class="n">dagloss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dagloss</span><span class="p">,</span>
                               <span class="n">dagpenalization</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dagpenalization</span><span class="p">,</span>
                               <span class="n">dagpenalization_increase</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dagpenalization_increase</span><span class="p">,</span>
                               <span class="n">losstype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losstype</span><span class="p">,</span>
                               <span class="n">linear</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span>
                               <span class="n">hlayers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hlayers</span><span class="p">,</span>
                               <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nruns</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">parallel_run</span><span class="p">(</span><span class="n">run_SAM</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">skeleton</span><span class="o">=</span><span class="n">skeleton</span><span class="p">,</span>
                                   <span class="n">nruns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nruns</span><span class="p">,</span>
                                   <span class="n">njobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">njobs</span><span class="p">,</span> <span class="n">gpus</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gpus</span><span class="p">,</span> <span class="n">lr_gen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
                                   <span class="n">lr_disc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dlr</span><span class="p">,</span>
                                   <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                                   <span class="n">lambda1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda1</span><span class="p">,</span> <span class="n">lambda2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda2</span><span class="p">,</span>
                                   <span class="n">nh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nh</span><span class="p">,</span> <span class="n">dnh</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dnh</span><span class="p">,</span>
                                   <span class="n">train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                                   <span class="n">test</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batchsize</span><span class="p">,</span>
                                   <span class="n">dagstart</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dagstart</span><span class="p">,</span>
                                   <span class="n">dagloss</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dagloss</span><span class="p">,</span>
                                   <span class="n">dagpenalization</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dagpenalization</span><span class="p">,</span>
                                   <span class="n">dagpenalization_increase</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dagpenalization_increase</span><span class="p">,</span>
                                   <span class="n">losstype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losstype</span><span class="p">,</span>
                                   <span class="n">linear</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span>
                                   <span class="n">hlayers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hlayers</span><span class="p">)</span>
        <span class="n">list_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_out</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">except</span> <span class="ne">AssertionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All solutions contain NaNs&quot;</span><span class="p">)</span>
            <span class="k">raise</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">list_out</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">list_out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nx</span><span class="o">.</span><span class="n">relabel_nodes</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">(</span><span class="n">W</span><span class="p">),</span>
                                <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span>
                                 <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)})</span></div>

    <span class="k">def</span> <span class="nf">orient_directed_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Orient a (partially directed) graph.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">orient_undirected_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Orient a undirected graph.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_graph_from_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate a causal graph out of observational data.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2018, Diviyan Kalainathan, Olivier Goudet

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>