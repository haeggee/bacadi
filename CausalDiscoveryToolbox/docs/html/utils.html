

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>cdt.utils &mdash; Causal Discovery Toolbox 0.5.22 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon.png"/>
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"extensions": ["tex2jax.js"], "jax": ["input/TeX", "output/HTML-CSS"], "tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "displayMath": [["$$", "$$"], ["\\[", "\\]"]], "processEscapes": true}, "HTML-CSS": {"fonts": ["TeX"]}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="cdt.metrics" href="metrics.html" />
    <link rel="prev" title="cdt.data" href="data.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/banner.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.5.22
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Causal Discovery Toolbox Documentation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Get started</a></li>
<li class="toctree-l1"><a class="reference internal" href="causality.html">cdt.causality</a></li>
<li class="toctree-l1"><a class="reference internal" href="independence.html">cdt.independence</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">cdt.data</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">cdt.utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-cdt.utils.R">cdt.utils.R</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-cdt.utils.io">cdt.utils.io</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-cdt.utils.graph">cdt.utils.graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-cdt.utils.loss">cdt.utils.loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-cdt.utils.parallel">cdt.utils.parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-cdt.utils.torch">cdt.utils.torch</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">cdt.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Toolbox Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">PyTorch Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer.html">Developer Documentation</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Causal Discovery Toolbox</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>cdt.utils</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/utils.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-cdt.utils">
<span id="cdt-utils"></span><h1>cdt.utils<a class="headerlink" href="#module-cdt.utils" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-cdt.utils.R">
<span id="cdt-utils-r"></span><h2>cdt.utils.R<a class="headerlink" href="#module-cdt.utils.R" title="Permalink to this headline">¶</a></h2>
<p>Loading and executing functions from R packages.</p>
<p>This module defines the interface between R and Python using subprocess.
At the initialization, the toolbox checks if R is available and sets
<code class="docutils literal notranslate"><span class="pre">cdt.SETTINGS.r_is_available</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> if the R framework is detected.
Else, this module is deactivated.</p>
<p>Next, each time an R function is called, the availability of the R package is
tested using the <code class="docutils literal notranslate"><span class="pre">DefaultRPackages.check_R_package</span></code> function. The number of
available packages is limited and the list is defined in <code class="docutils literal notranslate"><span class="pre">DefaultRPackages</span></code>.</p>
<p>If the package is available, the <code class="docutils literal notranslate"><span class="pre">launch_R_script</span></code> proceeds to the execution
of the function, by:</p>
<ol class="arabic simple">
<li><p>Copying the R script template and modifying it with the given arguments</p></li>
<li><p>Copying all the data to a temporary folder</p></li>
<li><p>Launching a R subprocess using the modified template and the data, and
the script saves the results in the temporary folder</p></li>
<li><p>Retrieving all the results in the Python process and cleaning up all the
temporary files.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For custom R configurations/path, a placeholder for the Rscript executable
path is available at <code class="docutils literal notranslate"><span class="pre">cdt.SETTINGS.rpath</span></code>. It should be overriden with
the full path as a string.</p>
</div>
<dl class="py class">
<dt id="cdt.utils.R.DefaultRPackages">
<em class="property">class </em><code class="sig-prename descclassname">cdt.utils.R.</code><code class="sig-name descname">DefaultRPackages</code><a class="reference internal" href="_modules/cdt/utils/R.html#DefaultRPackages"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.R.DefaultRPackages" title="Permalink to this definition">¶</a></dt>
<dd><p>Define the R packages that can be imported and checks their availability.</p>
<p>The attributes define all the R packages that can be imported. Their value
is initialized to <code class="docutils literal notranslate"><span class="pre">None</span></code> ; and as their are called, their availability
will be checked and their value will be set to either <cite>True</cite> or <cite>False</cite>
depending on the results. A package already tested (which value is not
<cite>None</cite>) will not be tested again.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pcalg</strong> (<em>bool</em>) – Availability of the <cite>pcalg</cite> R package</p></li>
<li><p><strong>kpcalg</strong> (<em>bool</em>) – Availability of the <cite>kpcalg</cite> R package</p></li>
<li><p><strong>bnlearn</strong> (<em>bool</em>) – Availability of the <cite>bnlearn</cite> R package</p></li>
<li><p><strong>D2C</strong> (<em>bool</em>) – Availability of the <cite>D2C</cite> R package</p></li>
<li><p><strong>SID</strong> (<em>bool</em>) – Availability of the <cite>SID</cite> R package</p></li>
<li><p><strong>CAM</strong> (<em>bool</em>) – Availability of the <cite>CAM</cite> R package</p></li>
<li><p><strong>RCIT</strong> (<em>bool</em>) – Availability of the <cite>RCIT</cite> R package</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The RCIT package is not the original one (github.com/ericstrobl/RCIT)
but an adaptation made to fit in the PC algorithm, available at:
<a class="reference external" href="https://github.com/Diviyan-Kalainathan/RCIT">https://github.com/Diviyan-Kalainathan/RCIT</a></p>
</div>
<dl class="py method">
<dt id="cdt.utils.R.DefaultRPackages.check_R_package">
<code class="sig-name descname">check_R_package</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">package</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/R.html#DefaultRPackages.check_R_package"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.R.DefaultRPackages.check_R_package" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a subprocess to check the package’s availability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>package</strong> (<em>str</em>) – Name of the package to be tested.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><cite>True</cite> if the package is available, <cite>False</cite> otherwise</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="cdt.utils.R.launch_R_script">
<code class="sig-prename descclassname">cdt.utils.R.</code><code class="sig-name descname">launch_R_script</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">template</span></em>, <em class="sig-param"><span class="n">arguments</span></em>, <em class="sig-param"><span class="n">output_function</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">debug</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/R.html#launch_R_script"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.R.launch_R_script" title="Permalink to this definition">¶</a></dt>
<dd><p>Launch an R script, starting from a template and replacing text in file
before execution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>template</strong> (<em>str</em>) – path to the template of the R script</p></li>
<li><p><strong>arguments</strong> (<em>dict</em>) – Arguments that modify the template’s placeholders
with arguments</p></li>
<li><p><strong>output_function</strong> (<em>function</em>) – Function to execute <strong>after</strong> the execution
of the R script, and its output is returned by this function. Used
traditionally as a function to retrieve the results of the
execution.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Sets the verbosity of the R subprocess.</p></li>
<li><p><strong>debug</strong> (<em>bool</em>) – If True, the generated scripts are not deleted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns the output of the <code class="docutils literal notranslate"><span class="pre">output_function</span></code> if not <cite>None</cite>
else <cite>True</cite> or <cite>False</cite> depending on whether the execution was
successful.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-cdt.utils.io">
<span id="cdt-utils-io"></span><h2>cdt.utils.io<a class="headerlink" href="#module-cdt.utils.io" title="Permalink to this headline">¶</a></h2>
<p>Formatting and import functions.</p>
<p>Author: Diviyan Kalainathan
Date : 2/06/17</p>
<dl class="py function">
<dt id="cdt.utils.io.read_causal_pairs">
<code class="sig-prename descclassname">cdt.utils.io.</code><code class="sig-name descname">read_causal_pairs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">filename</span></em>, <em class="sig-param"><span class="n">scale</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/io.html#read_causal_pairs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.io.read_causal_pairs" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert a ChaLearn Cause effect pairs challenge format into numpy.ndarray.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em><em> or </em><em>pandas.DataFrame</em>) – path of the file to read or DataFrame containing the data</p></li>
<li><p><strong>scale</strong> (<em>bool</em>) – Scale the data</p></li>
<li><p><strong>**kwargs</strong> – parameters to be passed to pandas.read_csv</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dataframe composed of (SampleID, a (numpy.ndarray) , b (numpy.ndarray))</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils</span> <span class="kn">import</span> <span class="n">read_causal_pairs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">read_causal_pairs</span><span class="p">(</span><span class="s1">&#39;file.tsv&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="cdt.utils.io.read_adjacency_matrix">
<code class="sig-prename descclassname">cdt.utils.io.</code><code class="sig-name descname">read_adjacency_matrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">filename</span></em>, <em class="sig-param"><span class="n">directed</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/io.html#read_adjacency_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.io.read_adjacency_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Read a file (containing an adjacency matrix) and convert it into a
directed or undirected networkx graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em><em> or </em><em>pandas.DataFrame</em>) – file to read or DataFrame containing the data</p></li>
<li><p><strong>directed</strong> (<em>bool</em>) – Return directed graph</p></li>
<li><p><strong>kwargs</strong> – extra parameters to be passed to pandas.read_csv</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>networkx graph containing the graph.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><strong>networkx.DiGraph</strong> or <strong>networkx.Graph</strong> depending on the
<code class="docutils literal notranslate"><span class="pre">directed</span></code> parameter.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils</span> <span class="kn">import</span> <span class="n">read_adjacency_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">read_causal_pairs</span><span class="p">(</span><span class="s1">&#39;graph_file.csv&#39;</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="cdt.utils.io.read_list_edges">
<code class="sig-prename descclassname">cdt.utils.io.</code><code class="sig-name descname">read_list_edges</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">filename</span></em>, <em class="sig-param"><span class="n">directed</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/io.html#read_list_edges"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.io.read_list_edges" title="Permalink to this definition">¶</a></dt>
<dd><p>Read a file (containing list of edges) and convert it into a directed
or undirected networkx graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em><em> or </em><em>pandas.DataFrame</em>) – file to read or DataFrame containing the data</p></li>
<li><p><strong>directed</strong> (<em>bool</em>) – Return directed graph</p></li>
<li><p><strong>kwargs</strong> – extra parameters to be passed to pandas.read_csv</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>networkx graph containing the graph.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><strong>networkx.DiGraph</strong> or <strong>networkx.Graph</strong> depending on the
<code class="docutils literal notranslate"><span class="pre">directed</span></code> parameter.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils</span> <span class="kn">import</span> <span class="n">read_adjacency_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">read_causal_pairs</span><span class="p">(</span><span class="s1">&#39;graph_file.csv&#39;</span><span class="p">,</span> <span class="n">directed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="module-cdt.utils.graph">
<span id="cdt-utils-graph"></span><h2>cdt.utils.graph<a class="headerlink" href="#module-cdt.utils.graph" title="Permalink to this headline">¶</a></h2>
<p>Utilities for graph not included in Networkx.</p>
<dl class="py function">
<dt id="cdt.utils.graph.network_deconvolution">
<code class="sig-prename descclassname">cdt.utils.graph.</code><code class="sig-name descname">network_deconvolution</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mat</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/graph.html#network_deconvolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.graph.network_deconvolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Python implementation/translation of network deconvolution by MIT-KELLIS LAB.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For networkx graphs, use the cdt.utils.graph.remove_indirect_links function
code author:gidonro [Github username](https://github.com/gidonro/Network-Deconvolution)</p>
<p>LICENSE: MIT-KELLIS LAB</p>
<p>AUTHORS:
Algorithm was programmed by Soheil Feizi.
Paper authors are S. Feizi, D. Marbach,  M. M?©dard and M. Kellis
Python implementation: Gideon Rosenthal</p>
<p>For more details, see the following paper:
Network Deconvolution as a General Method to Distinguish
Direct Dependencies over Networks</p>
<p>By: Soheil Feizi, Daniel Marbach,  Muriel Médard and Manolis Kellis
Nature Biotechnology</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mat</strong> (<em>numpy.ndarray</em>) – matrix, if it is a square matrix, the program assumes
it is a relevance matrix where mat(i,j) represents the similarity content
between nodes i and j. Elements of matrix should be
non-negative.</p></li>
<li><p><strong>beta</strong> (<em>float</em>) – Scaling parameter, the program maps the largest absolute eigenvalue
of the direct dependency matrix to beta. It should be
between 0 and 1.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – fraction of edges of the observed dependency matrix to be kept in
deconvolution process.</p></li>
<li><p><strong>control</strong> (<em>int</em>) – if 0, displaying direct weights for observed
interactions, if 1, displaying direct weights for both observed and
non-observed interactions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output deconvolved matrix (direct dependency matrix). Its components
represent direct edge weights of observed interactions.
Choosing top direct interactions (a cut-off) depends on the application and
is not implemented in this code.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils.graph</span> <span class="kn">import</span> <span class="n">network_deconvolution</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate sample data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.data</span> <span class="kn">import</span> <span class="n">AcyclicGraphGenerator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">graph</span> <span class="o">=</span> <span class="n">AcyclicGraphGenerator</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adj_mat</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">network_deconvolution</span><span class="p">(</span><span class="n">adj_mat</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>To apply ND on regulatory networks, follow steps explained in Supplementary notes
1.4.1 and 2.1 and 2.3 of the paper.
In this implementation, input matrices are made symmetric.</p>
</div>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt id="cdt.utils.graph.aracne">
<code class="sig-prename descclassname">cdt.utils.graph.</code><code class="sig-name descname">aracne</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">m</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/graph.html#aracne"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.graph.aracne" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of the ARACNE algorithm.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For networkx graphs, use the cdt.utils.graph.remove_indirect_links function</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mat</strong> (<em>numpy.ndarray</em>) – matrix, if it is a square matrix, the program assumes
it is a relevance matrix where mat(i,j) represents the similarity content
between nodes i and j. Elements of matrix should be
non-negative.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output deconvolved matrix (direct dependency matrix). Its components
represent direct edge weights of observed interactions.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils.graph</span> <span class="kn">import</span> <span class="n">aracne</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate sample data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.data</span> <span class="kn">import</span> <span class="n">AcyclicGraphGenerator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">graph</span> <span class="o">=</span> <span class="n">AcyclicGraphGenerator</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adj_mat</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">aracne</span><span class="p">(</span><span class="n">adj_mat</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ref: ARACNE: An Algorithm for the Reconstruction of Gene Regulatory Networks in a Mammalian Cellular Context
Adam A Margolin, Ilya Nemenman, Katia Basso, Chris Wiggins, Gustavo Stolovitzky, Riccardo Dalla Favera and Andrea Califano
DOI: <a class="reference external" href="https://doi.org/10.1186/1471-2105-7-S1-S7">https://doi.org/10.1186/1471-2105-7-S1-S7</a></p>
</div>
</dd></dl>

<dl class="py function">
<dt id="cdt.utils.graph.clr">
<code class="sig-prename descclassname">cdt.utils.graph.</code><code class="sig-name descname">clr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">M</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/graph.html#clr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.graph.clr" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of the Context Likelihood or Relatedness Network algorithm.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For networkx graphs, use the cdt.utils.graph.remove_indirect_links function</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mat</strong> (<em>numpy.ndarray</em>) – matrix, if it is a square matrix, the program assumes
it is a relevance matrix where mat(i,j) represents the similarity content
between nodes i and j. Elements of matrix should be
non-negative.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output deconvolved matrix (direct dependency matrix). Its components
represent direct edge weights of observed interactions.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils.graph</span> <span class="kn">import</span> <span class="n">clr</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate sample data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.data</span> <span class="kn">import</span> <span class="n">AcyclicGraphGenerator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">graph</span> <span class="o">=</span> <span class="n">AcyclicGraphGenerator</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adj_mat</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">clr</span><span class="p">(</span><span class="n">adj_mat</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ref:Jeremiah J. Faith, Boris Hayete, Joshua T. Thaden, Ilaria Mogno, Jamey
Wierzbowski, Guillaume Cottarel, Simon Kasif, James J. Collins, and Timothy
S. Gardner. Large-scale mapping and validation of escherichia coli
transcriptional regulation from a compendium of expression profiles.
PLoS Biology, 2007</p>
</div>
</dd></dl>

<dl class="py function">
<dt id="cdt.utils.graph.remove_indirect_links">
<code class="sig-prename descclassname">cdt.utils.graph.</code><code class="sig-name descname">remove_indirect_links</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">g</span></em>, <em class="sig-param"><span class="n">alg</span><span class="o">=</span><span class="default_value">'aracne'</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/graph.html#remove_indirect_links"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.graph.remove_indirect_links" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply deconvolution to a networkx graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>g</strong> (<em>networkx.Graph</em>) – Graph to apply deconvolution to</p></li>
<li><p><strong>alg</strong> (<em>str</em>) – Algorithm to use (‘aracne’, ‘clr’, ‘nd’)</p></li>
<li><p><strong>kwargs</strong> (<em>dict</em>) – extra options for algorithms</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>graph with undirected links removed.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>networkx.Graph</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils.graph</span> <span class="kn">import</span> <span class="n">remove_indirect_links</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate sample data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.data</span> <span class="kn">import</span> <span class="n">AcyclicGraphGenerator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">graph</span> <span class="o">=</span> <span class="n">AcyclicGraphGenerator</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">remove_indirect_links</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">alg</span><span class="o">=</span><span class="s1">&#39;aracne&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="cdt.utils.graph.dagify_min_edge">
<code class="sig-prename descclassname">cdt.utils.graph.</code><code class="sig-name descname">dagify_min_edge</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">g</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/graph.html#dagify_min_edge"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.graph.dagify_min_edge" title="Permalink to this definition">¶</a></dt>
<dd><p>Input a graph and output a DAG.</p>
<p>The heuristic is to reverse the edge with the lowest score of the cycle
if possible, else remove it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>g</strong> (<em>networkx.DiGraph</em>) – Graph to modify to output a DAG</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>DAG made out of the input graph.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>networkx.DiGraph</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils.graph</span> <span class="kn">import</span> <span class="n">dagify_min_edge</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate sample data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span> <span class="o">*</span>
<span class="go">                       np.random.uniform(size=(4,4)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">dagify_min_edge</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="module-cdt.utils.loss">
<span id="cdt-utils-loss"></span><h2>cdt.utils.loss<a class="headerlink" href="#module-cdt.utils.loss" title="Permalink to this headline">¶</a></h2>
<p>Pytorch implementation of Losses and tools.</p>
<dl class="py class">
<dt id="cdt.utils.loss.MMDloss">
<em class="property">class </em><code class="sig-prename descclassname">cdt.utils.loss.</code><code class="sig-name descname">MMDloss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_size</span></em>, <em class="sig-param"><span class="n">bandwidths</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/loss.html#MMDloss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.loss.MMDloss" title="Permalink to this definition">¶</a></dt>
<dd><p><strong>[torch.nn.Module]</strong> Maximum Mean Discrepancy Metric to compare
empirical distributions.</p>
<p>The MMD score is defined by:</p>
<div class="math notranslate nohighlight">
\[\widehat{MMD_k}(\mathcal{D}, \widehat{\mathcal{D}}) =
\frac{1}{n^2} \sum_{i, j = 1}^{n} k(x_i, x_j) + \frac{1}{n^2}
\sum_{i, j = 1}^{n} k(\hat{x}_i, \hat{x}_j) - \frac{2}{n^2}
\sum_{i,j = 1}^n k(x_i, \hat{x}_j)\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{D} \text{ and } \widehat{\mathcal{D}}\)</span> represent
respectively the observed and empirical distributions, <span class="math notranslate nohighlight">\(k\)</span> represents
the RBF kernel and <span class="math notranslate nohighlight">\(n\)</span> the batch size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<em>int</em>) – Fixed batch size.</p></li>
<li><p><strong>bandwiths</strong> (<em>list</em>) – List of bandwiths to take account of. Defaults at
[0.01, 0.1, 1, 10, 100]</p></li>
<li><p><strong>device</strong> (<em>str</em>) – PyTorch device on which the computation will be made.
Defaults at <code class="docutils literal notranslate"><span class="pre">cdt.SETTINGS.default_device</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs: empirical, observed</dt><dd><p>Forward pass: Takes both the true samples and the generated sample in any order
and returns the MMD score between the two empirical distributions.</p>
<ul class="simple">
<li><p><strong>empirical</strong> distribution of shape <cite>(batch_size, features)</cite>: torch.Tensor
containing the empirical distribution</p></li>
<li><p><strong>observed</strong> distribution of shape <cite>(batch_size, features)</cite>: torch.Tensor
containing the observed distribution.</p></li>
</ul>
</dd>
<dt>Outputs: score</dt><dd><ul class="simple">
<li><p><strong>score</strong> of shape <cite>(1)</cite>: Torch.Tensor containing the loss value.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ref: Gretton, A., Borgwardt, K. M., Rasch, M. J., Schölkopf,
B., &amp; Smola, A. (2012). A kernel two-sample test.
Journal of Machine Learning Research, 13(Mar), 723-773.</p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils.loss</span> <span class="kn">import</span> <span class="n">MMDloss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">th</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mmd</span> <span class="o">=</span> <span class="n">MMDloss</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># 100 is the batch size</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mmd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">0.0766</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt id="cdt.utils.loss.MomentMatchingLoss">
<em class="property">class </em><code class="sig-prename descclassname">cdt.utils.loss.</code><code class="sig-name descname">MomentMatchingLoss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n_moments</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/loss.html#MomentMatchingLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.loss.MomentMatchingLoss" title="Permalink to this definition">¶</a></dt>
<dd><p><strong>[torch.nn.Module]</strong> L2 Loss between k-moments between two
distributions, k being a parameter.</p>
<p>These moments are raw moments and not normalized.
The loss is an L2 loss between the moments:</p>
<div class="math notranslate nohighlight">
\[MML(X, Y) = \sum_{m=1}^{m^*} \left( \frac{1}{n_x} \sum_{i=1}^{n_x} {x_i}^m
- \frac{1}{n_y} \sum_{j=1}^{n_y} {y_j}^m \right)^2\]</div>
<p>where <span class="math notranslate nohighlight">\(m^*\)</span> represent the number of moments to compute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n_moments</strong> (<em>int</em>) – Number of moments to compute.</p>
</dd>
</dl>
<dl class="simple">
<dt>Input: (X, Y)</dt><dd><ul class="simple">
<li><p><strong>X</strong> represents the first empirical distribution in a torch.Tensor of
shape <cite>(?, features)</cite></p></li>
<li><p><strong>Y</strong> represents the second empirical distribution in a torch.Tensor of
shape <cite>(?, features)</cite></p></li>
</ul>
</dd>
<dt>Output: mml</dt><dd><ul class="simple">
<li><p><strong>mml</strong> is the output of the forward pass and is differenciable.
torch.Tensor of shape <cite>(1)</cite></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils.loss</span> <span class="kn">import</span> <span class="n">MomentMatchingLoss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">th</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mml</span> <span class="o">=</span> <span class="n">MomentMatchingLoss</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mml</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt id="cdt.utils.loss.TTestCriterion">
<em class="property">class </em><code class="sig-prename descclassname">cdt.utils.loss.</code><code class="sig-name descname">TTestCriterion</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">max_iter</span></em>, <em class="sig-param"><span class="n">runs_per_iter</span></em>, <em class="sig-param"><span class="n">threshold</span><span class="o">=</span><span class="default_value">0.01</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/loss.html#TTestCriterion"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.loss.TTestCriterion" title="Permalink to this definition">¶</a></dt>
<dd><p>A loop criterion based on t-test to check significance of results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_iter</strong> (<em>int</em>) – Maximum number of iterations authorized</p></li>
<li><p><strong>runs_per_iter</strong> (<em>int</em>) – Number of runs performed per iteration</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) – p-value threshold, under which the loop is stopped.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cdt.utils.loss</span> <span class="kn">import</span> <span class="n">TTestCriterion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">TTestCriterion</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">while</span> <span class="n">l</span><span class="o">.</span><span class="n">loop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="go">    ...     # compute loop and update results in x, y</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span>  <span class="c1"># Two lists with significant difference in score</span>
</pre></div>
</div>
<dl class="py method">
<dt id="cdt.utils.loss.TTestCriterion.loop">
<code class="sig-name descname">loop</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xy</span></em>, <em class="sig-param"><span class="n">yx</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/loss.html#TTestCriterion.loop"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.loss.TTestCriterion.loop" title="Permalink to this definition">¶</a></dt>
<dd><p>Tests the loop condition based on the new results and the
parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xy</strong> (<em>list</em>) – list containing all the results for one set of samples</p></li>
<li><p><strong>yx</strong> (<em>list</em>) – list containing all the results for the other set.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if the loop has to continue, False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="cdt.utils.loss.notears_constr">
<code class="sig-prename descclassname">cdt.utils.loss.</code><code class="sig-name descname">notears_constr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">adj_m</span></em>, <em class="sig-param"><span class="n">max_pow</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/loss.html#notears_constr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.loss.notears_constr" title="Permalink to this definition">¶</a></dt>
<dd><p>No Tears constraint for binary adjacency matrixes. Represents a
differenciable constraint to converge towards a DAG.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If adj_m is non binary: Feed adj_m * adj_m as input (Hadamard product).</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>adj_m</strong> (<em>array-like</em>) – Adjacency matrix of the graph</p></li>
<li><p><strong>max_pow</strong> (<em>int</em>) – maximum value to which the infinite sum is to be computed.
defaults to the shape of the adjacency_matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Scalar value of the loss with the type</dt><dd><p>depending on the input.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>np.ndarray or torch.Tensor</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Zheng, X., Aragam, B., Ravikumar, P. K., &amp; Xing, E. P. (2018). DAGs with
NO TEARS: Continuous Optimization for Structure Learning. In Advances in
Neural Information Processing Systems (pp. 9472-9483).</p>
</div>
</dd></dl>

</div>
<div class="section" id="module-cdt.utils.parallel">
<span id="cdt-utils-parallel"></span><h2>cdt.utils.parallel<a class="headerlink" href="#module-cdt.utils.parallel" title="Permalink to this headline">¶</a></h2>
<p>This module introduces tools for execution of jobs in parallel.</p>
<p>Per default, joblib is used for easy and efficient execution of parallel tasks.
However, joblib does not support GPU management, and does not kill processes
at the end of each task, thus keeping in GPU memory the pytorch execution
context.</p>
<p>This module introduces equivalent tools for multiprocessing while
avoiding GPU memory leak. This tool provides functions that make use
GPUs: otherwise, joblib is called.</p>
<dl class="py function">
<dt id="cdt.utils.parallel.parallel_run">
<code class="sig-prename descclassname">cdt.utils.parallel.</code><code class="sig-name descname">parallel_run</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">function</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="n">nruns</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">njobs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">gpus</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/parallel.html#parallel_run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.parallel.parallel_run" title="Permalink to this definition">¶</a></dt>
<dd><p>Mutiprocessed execution of a function with parameters, with GPU management.</p>
<p>This function is useful when the used wants to execute a bootstrap on a
function on GPU devices, as joblib does not include such feature.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>function</strong> (<em>function</em>) – Function to execute.</p></li>
<li><p><strong>*args</strong> – arguments going to be fed to the function.</p></li>
<li><p><strong>nruns</strong> (<em>int</em>) – Total number of executions of the function.</p></li>
<li><p><strong>njobs</strong> (<em>int</em>) – Number of parallel executions (defaults to <code class="docutils literal notranslate"><span class="pre">cdt.SETTINGS.NJOBS</span></code>).</p></li>
<li><p><strong>gpus</strong> (<em>int</em>) – Number of GPU devices allocated to the job (defaults to <code class="docutils literal notranslate"><span class="pre">cdt.SETTINGS.GPU</span></code>)</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments going to be fed to the function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>concatenated list of outputs of executions. The order of elements
does not correspond to the initial order.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="cdt.utils.parallel.parallel_run_generator">
<code class="sig-prename descclassname">cdt.utils.parallel.</code><code class="sig-name descname">parallel_run_generator</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">function</span></em>, <em class="sig-param"><span class="n">generator</span></em>, <em class="sig-param"><span class="n">njobs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">gpus</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/parallel.html#parallel_run_generator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.parallel.parallel_run_generator" title="Permalink to this definition">¶</a></dt>
<dd><p>Mutiprocessed execution of a function with parameters, with GPU management.</p>
<p>Variant of the <code class="docutils literal notranslate"><span class="pre">`cdt.utils.parallel.parallel_run`</span></code> function, with the
exception that this function takes an iterable as args, kwargs and nruns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>function</strong> (<em>function</em>) – Function to execute.</p></li>
<li><p><strong>*args</strong> – arguments going to be fed to the function.</p></li>
<li><p><strong>generator</strong> (<em>iterable</em>) – generator or list with the arguments
for each run, each element much be a tuple of ([args], {kwargs}).</p></li>
<li><p><strong>njobs</strong> (<em>int</em>) – Number of parallel executions (defaults to <code class="docutils literal notranslate"><span class="pre">cdt.SETTINGS.NJOBS</span></code>).</p></li>
<li><p><strong>gpus</strong> (<em>int</em>) – Number of GPU devices allocated to the job (defaults to <code class="docutils literal notranslate"><span class="pre">cdt.SETTINGS.GPU</span></code>)</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments going to be fed to the function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>concatenated list of outputs of executions. The order of elements
does correspond to the initial order.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-cdt.utils.torch">
<span id="cdt-utils-torch"></span><h2>cdt.utils.torch<a class="headerlink" href="#module-cdt.utils.torch" title="Permalink to this headline">¶</a></h2>
<p>PyTorch utilities for models.</p>
<p>Author: Diviyan Kalainathan, Olivier Goudet
Date: 09/3/2018</p>
<dl class="py class">
<dt id="cdt.utils.torch.ChannelBatchNorm1d">
<em class="property">class </em><code class="sig-prename descclassname">cdt.utils.torch.</code><code class="sig-name descname">ChannelBatchNorm1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_channels</span></em>, <em class="sig-param"><span class="n">num_features</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/torch.html#ChannelBatchNorm1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.torch.ChannelBatchNorm1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D
inputs with optional additional channel dimension) as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a> .</p>
<p>Variant which is adapted for the SAM model, where the Channel dimension is
considered as extra-features. Thus considering the input as a
<cite>N x (channels * in_features)</cite> tensor.</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - \mathrm{E}[x]}{\sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta\]</div>
<p>The mean and standard-deviation are calculated per-dimension over
the mini-batches and <span class="math notranslate nohighlight">\(\gamma\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> are learnable parameter vectors
of size <cite>C</cite> (where <cite>C</cite> is the input size).</p>
<p>By default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code>
of 0.1.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">track_running_stats</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> argument is different from one used in optimizer
classes and the conventional notion of momentum. Mathematically, the
update rule for running statistics here is
<span class="math notranslate nohighlight">\(\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t\)</span>,
where <span class="math notranslate nohighlight">\(\hat{x}\)</span> is the estimated statistic and <span class="math notranslate nohighlight">\(x_t\)</span> is the
new observed value.</p>
</div>
<p>Because the Batch Normalization is done over the <cite>C</cite> dimension, computing statistics
on <cite>(N, L)</cite> slices, it’s common terminology to call this Temporal Batch Normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – <span class="math notranslate nohighlight">\(C\)</span> from an expected input of size
<span class="math notranslate nohighlight">\((N, C, L)\)</span> or <span class="math notranslate nohighlight">\(L\)</span> from input of size <span class="math notranslate nohighlight">\((N, L)\)</span></p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability.
Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var
computation. Can be set to <code class="docutils literal notranslate"><span class="pre">None</span></code> for cumulative moving average
(i.e. simple average). Default: 0.1</p></li>
<li><p><strong>affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module has
learnable affine parameters. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>track_running_stats</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this
module tracks the running mean and variance, and when set to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((N, C)\)</span> or <span class="math notranslate nohighlight">\((N, C, L)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((N, C)\)</span> or <span class="math notranslate nohighlight">\((N, C, L)\)</span> (same shape as input)</p></li>
</ul>
</dd>
<dt>Examples::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="py method">
<dt id="cdt.utils.torch.ChannelBatchNorm1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/torch.html#ChannelBatchNorm1d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.torch.ChannelBatchNorm1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="cdt.utils.torch.Linear3D">
<em class="property">class </em><code class="sig-prename descclassname">cdt.utils.torch.</code><code class="sig-name descname">Linear3D</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sizes</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/torch.html#Linear3D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.torch.Linear3D" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a linear transformation to the incoming data: <span class="math notranslate nohighlight">\(y = Ax + b\)</span>.
Broadcasts following a 3rd dimension. If input is 2d, input is repeated over
all channels. This layer is a linear layer with 3D parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sizes</strong> – Triplet of int values defining the shape of the 3D tensor:
(channels, in_features, out_features)</p></li>
<li><p><strong>bias</strong> – If set to False, the layer will not learn an additive bias.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Variables</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>weight</strong> (<em>torch.Tensor</em>) – the learnable weights of the module of shape
<cite>(out_features x in_features)</cite></p></li>
<li><p><strong>bias</strong> (<em>torch.Tensor</em>) – the learnable bias of the module of shape <cite>(out_features)</cite></p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((N, *, in\_features)\)</span> where <span class="math notranslate nohighlight">\(*\)</span> means number of
channels or no additional dimension.</p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((N, channels, out\_features)\)</span>.</p></li>
</ul>
</dd>
<dt>Examples::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">cdt</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">Linear3D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="py method">
<dt id="cdt.utils.torch.Linear3D.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/torch.html#Linear3D.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.torch.Linear3D.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="py method">
<dt id="cdt.utils.torch.Linear3D.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">noise</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">adj_matrix</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/torch.html#Linear3D.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.torch.Linear3D.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="cdt.utils.torch.gumbel_softmax">
<code class="sig-prename descclassname">cdt.utils.torch.</code><code class="sig-name descname">gumbel_softmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">logits</span></em>, <em class="sig-param"><span class="n">tau</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">hard</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">eps</span><span class="o">=</span><span class="default_value">1e-10</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/torch.html#gumbel_softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.torch.gumbel_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of pytorch.
(<a class="reference external" href="https://github.com/pytorch/pytorch/blob/e4eee7c2cf43f4edba7a14687ad59d3ed61d9833/torch/nn/functional.py">https://github.com/pytorch/pytorch/blob/e4eee7c2cf43f4edba7a14687ad59d3ed61d9833/torch/nn/functional.py</a>)
Sample from the Gumbel-Softmax distribution and optionally discretize.
:param logits: <cite>[batch_size, n_class]</cite> unnormalized log-probs
:param tau: non-negative scalar temperature
:param hard: if <code class="docutils literal notranslate"><span class="pre">True</span></code>, take <cite>argmax</cite>, but differentiate w.r.t. soft sample y</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>[batch_size, n_class] sample from the Gumbel-Softmax distribution.
If hard=True, then the returned sample will be one-hot, otherwise it will
be a probability distribution that sums to 1 across classes</p>
</dd>
</dl>
<p>Constraints:
- this implementation only works on batch_size x num_features tensor for now
based on
<a class="reference external" href="https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb">https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb</a> ,
(MIT license)</p>
</dd></dl>

<dl class="py class">
<dt id="cdt.utils.torch.MatrixSampler">
<em class="property">class </em><code class="sig-prename descclassname">cdt.utils.torch.</code><code class="sig-name descname">MatrixSampler</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">graph_size</span></em>, <em class="sig-param"><span class="n">mask</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">gumbel</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/torch.html#MatrixSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.torch.MatrixSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix Sampler, following a Bernoulli distribution. with learnable
parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph_size</strong> (<em>int</em><em> or </em><em>tuple</em>) – shape of the matrix to sample. If is int,
samples a square matrix.</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Allows to forbid some elements to be sampled.
Defaults to <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">th.eye()</span></code>.</p></li>
<li><p><strong>gumbel</strong> (<em>bool</em>) – Use either gumbel softmax (True) or gumbel sigmoid (False)</p></li>
</ul>
</dd>
<dt class="field-even">Variables</dt>
<dd class="field-even"><p><strong>weights</strong> – the learnable weights of the module of shape
<cite>(graph_size x graph_size)</cite> if the input was <cite>int</cite> else <cite>(*graph_size)</cite></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>output: <cite>graph_size</cite> if tuple given, else <cite>(graph_size, graph_size)</cite></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="cdt.utils.torch.MatrixSampler.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">tau</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">drawhard</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cdt/utils/torch.html#MatrixSampler.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#cdt.utils.torch.MatrixSampler.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a sampled graph.</p>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="metrics.html" class="btn btn-neutral float-right" title="cdt.metrics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="data.html" class="btn btn-neutral float-left" title="cdt.data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2018, Diviyan Kalainathan, Olivier Goudet

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>